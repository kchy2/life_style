import os
import json
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì°¾ê¸°)
# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ì—ì„œ ìƒìœ„ ë””ë ‰í† ë¦¬(í”„ë¡œì íŠ¸ ë£¨íŠ¸)ë¡œ ì´ë™
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
env_path = os.path.join(project_root, '.env')

# .env íŒŒì¼ ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ëª…ì‹œ)
load_dotenv(dotenv_path=env_path)

# í”„ë¡¬í”„íŠ¸ íŒŒì¼ì—ì„œ ì½ì–´ì˜¤ê¸°
def load_ai_prompt():
    """AI ì¡°ì–¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
    try:
        with open("prompt.md", "r", encoding="utf-8") as f:
            content = f.read()
            # export const AI_ADVICE_PROMPT = `...` í˜•ì‹ì—ì„œ í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ
            start = content.find("`") + 1
            end = content.rfind("`")
            if start > 0 and end > start:
                return content[start:end].strip()
    except:
        pass
    
    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
    return """ë„ˆëŠ” ì›¹ ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©ìì—ê²Œ ì¡°ì–¸ì„ í•´ì£¼ëŠ” AI ì½”ì¹˜ì•¼.

**ì¤‘ìš”: ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•´. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆ.**

**ì¶œë ¥ í˜•ì‹:**
{
  "summary": "í•œ ì¤„ ìš”ì•½ (50ì ì´ë‚´)",
  "advices": [
    {
      "title": "ì¡°ì–¸ ì œëª©",
      "description": "ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì¡°ì–¸ ì„¤ëª…",
      "priority": 1
    },
    {
      "title": "ì¡°ì–¸ ì œëª©",
      "description": "ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì¡°ì–¸ ì„¤ëª…",
      "priority": 2
    },
    {
      "title": "ì¡°ì–¸ ì œëª©",
      "description": "ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì¡°ì–¸ ì„¤ëª…",
      "priority": 3
    }
  ],
  "timestamp": "YYYY-MM-DD HH:MM:SS í˜•ì‹ì˜ í˜„ì¬ ì‹œê°„"
}

**ê·œì¹™:**
1. JSON í˜•ì‹ë§Œ ì¶œë ¥ (ë§ˆí¬ë‹¤ìš´, ì½”ë“œ ë¸”ë¡ ì—†ì´)
2. summaryëŠ” 50ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
3. advices ë°°ì—´ì€ ë°˜ë“œì‹œ 3ê°œì˜ ì¡°ì–¸ í¬í•¨
4. priorityëŠ” 1(ê°€ì¥ ì¤‘ìš”)ë¶€í„° 3ê¹Œì§€
5. descriptionì€ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ í–‰ë™ ì§€ì¹¨
6. timestampëŠ” ISO 8601 í˜•ì‹ ë˜ëŠ” "YYYY-MM-DD HH:MM:SS" í˜•ì‹"""

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
def get_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± (.env íŒŒì¼ì—ì„œ API í‚¤ ì½ê¸°)"""
    # .env íŒŒì¼ì—ì„œ API í‚¤ ì½ê¸°
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì§ì ‘ í™•ì¸
        api_key = os.environ.get("OPENAI_API_KEY")
    
    if not api_key:
        # .env íŒŒì¼ ê²½ë¡œ í™•ì¸
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(current_dir)
        env_path = os.path.join(project_root, '.env')
        
        error_msg = "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
        if os.path.exists(env_path):
            error_msg += f"âœ… .env íŒŒì¼ì€ ì¡´ì¬í•©ë‹ˆë‹¤: {env_path}\n"
            error_msg += "âš ï¸ .env íŒŒì¼ì— ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”:\n"
            error_msg += "   OPENAI_API_KEY=sk-your-api-key-here\n"
        else:
            error_msg += f"âŒ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {env_path}\n"
            error_msg += "ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— .env íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”:\n"
            error_msg += "   OPENAI_API_KEY=sk-your-api-key-here\n"
        
        error_msg += "\nğŸ’¡ OpenAI API í‚¤ëŠ” https://platform.openai.com/api-keys ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        raise ValueError(error_msg)
    
    return OpenAI(api_key=api_key)

def load_routine_data_for_advice() -> str:
    """routine_data_v2.csv íŒŒì¼ì„ ì½ì–´ì„œ ì¡°ì–¸ì— ì‚¬ìš©í•  ë°ì´í„° ë¬¸ìì—´ ë°˜í™˜"""
    try:
        csv_path = "routine_data_v2.csv"
        if not os.path.exists(csv_path):
            csv_path = os.path.join(os.path.dirname(__file__), "..", "routine_data_v2.csv")
        
        if os.path.exists(csv_path):
            import pandas as pd
            df = pd.read_csv(csv_path, encoding='utf-8')
            
            # ë°ì´í„° ìš”ì•½ ì •ë³´ ìƒì„±
            summary_lines = []
            summary_lines.append("=== ì‚¬ìš©ì ë£¨í‹´ ë°ì´í„° ìš”ì•½ ===\n")
            
            # ë‚ ì§œë³„ í†µê³„
            date_counts = df['ë‚ ì§œ'].value_counts().sort_index()
            summary_lines.append(f"ê¸°ë¡ëœ ë‚ ì§œ: {len(date_counts)}ì¼")
            summary_lines.append(f"ê¸°ê°„: {df['ë‚ ì§œ'].min()} ~ {df['ë‚ ì§œ'].max()}\n")
            
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            category_stats = df['ì¹´í…Œê³ ë¦¬'].value_counts()
            summary_lines.append("ì¹´í…Œê³ ë¦¬ë³„ í™œë™ íšŸìˆ˜:")
            for cat, count in category_stats.items():
                summary_lines.append(f"  - {cat}: {count}íšŒ")
            summary_lines.append("")
            
            # ì „ì²´ í™œë™ ë°ì´í„° (ì¡°ì–¸ì— í•„ìš”í•œ ëª¨ë“  ì •ë³´)
            summary_lines.append("ì „ì²´ í™œë™ ê¸°ë¡:")
            for idx, row in df.iterrows():
                memo_text = str(row['ë©”ëª¨']).strip() if pd.notna(row['ë©”ëª¨']) else ""
                if memo_text:
                    summary_lines.append(f"  [{row['ë‚ ì§œ']}] {row['ì‹œê°„(ì‹œì‘-ì¢…ë£Œ)']} | {row['í™œë™ëª…']} | {row['ì¹´í…Œê³ ë¦¬']} | ë©”ëª¨: {memo_text}")
                else:
                    summary_lines.append(f"  [{row['ë‚ ì§œ']}] {row['ì‹œê°„(ì‹œì‘-ì¢…ë£Œ)']} | {row['í™œë™ëª…']} | {row['ì¹´í…Œê³ ë¦¬']}")
            summary_lines.append("")
            
            # AI ê°œì… í™•ì¸
            dynamic_count = df['ë©”ëª¨'].astype(str).str.contains('[ë™ì  ë£¨í‹´]', na=False).sum()
            micro_count = df['ë©”ëª¨'].astype(str).str.contains('[ë§ˆì´í¬ë¡œ ë£¨í‹´]', na=False).sum()
            if dynamic_count > 0 or micro_count > 0:
                summary_lines.append(f"AI ê°œì… ì´ë ¥: ë™ì  ë£¨í‹´ {dynamic_count}íšŒ, ë§ˆì´í¬ë¡œ ë£¨í‹´ {micro_count}íšŒ\n")
            
            # ìˆ˜ë©´ íŒ¨í„´ ë¶„ì„
            sleep_records = df[df['ì¹´í…Œê³ ë¦¬'] == 'ìˆ˜ë©´']
            if len(sleep_records) > 0:
                summary_lines.append("ìˆ˜ë©´ íŒ¨í„´:")
                for idx, row in sleep_records.tail(3).iterrows():
                    summary_lines.append(f"  - {row['ë‚ ì§œ']} {row['ì‹œê°„(ì‹œì‘-ì¢…ë£Œ)']}: {row['ë©”ëª¨'] if pd.notna(row['ë©”ëª¨']) else ''}")
                summary_lines.append("")
            
            return "\n".join(summary_lines)
        else:
            return "CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        print(f"CSV ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def load_database_records_for_feedback() -> str:
    """ë°ì´í„°ë² ì´ìŠ¤ì˜ ê¸°ë¡ì„ ì½ì–´ì„œ í†µê³„ ê¸°ë°˜ ì¢…í•© í”¼ë“œë°±ì— ì‚¬ìš©í•  ë°ì´í„° ë¬¸ìì—´ ë°˜í™˜"""
    try:
        from database import get_all_records, get_statistics
        from datetime import datetime, timedelta
        
        all_records = get_all_records()
        
        if not all_records:
            return "ê¸°ë¡ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ë°ì´í„° ìš”ì•½ ì •ë³´ ìƒì„±
        summary_lines = []
        summary_lines.append("=== í†µê³„ ê¸°ë°˜ ì¢…í•© ë¶„ì„ ë°ì´í„° ===\n")
        
        # ì „ì²´ í†µê³„ ì •ë³´
        stats = get_statistics()
        summary_lines.append("ğŸ“Š ì „ì²´ í†µê³„ ìš”ì•½:")
        summary_lines.append(f"  - ì´ ê¸°ë¡ ìˆ˜: {stats['total_records']}ê°œ")
        
        # ë‚ ì§œë³„ í†µê³„
        dates = [r['date'] for r in all_records]
        unique_dates = len(set(dates))
        min_date = min(dates)
        max_date = max(dates)
        summary_lines.append(f"  - ê¸°ë¡ëœ ë‚ ì§œ: {unique_dates}ì¼")
        summary_lines.append(f"  - ê¸°ê°„: {min_date} ~ {max_date}")
        
        # ìµœê·¼ 7ì¼ ê¸°ë¡ ìˆ˜
        today = datetime.now().date()
        week_ago = today - timedelta(days=7)
        recent_week_records = [r for r in all_records if r['date'] >= week_ago.isoformat()]
        summary_lines.append(f"  - ìµœê·¼ 7ì¼ ê¸°ë¡ ìˆ˜: {len(recent_week_records)}ê°œ")
        summary_lines.append("")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ í†µê³„
        category_counts = {}
        category_times = {}
        category_avg_times = {}
        category_records_list = {}
        
        for record in all_records:
            cat = record['category']
            category_counts[cat] = category_counts.get(cat, 0) + 1
            
            if cat not in category_records_list:
                category_records_list[cat] = []
            category_records_list[cat].append(record)
            
            # ì‹œê°„ ê³„ì‚°
            try:
                start = datetime.strptime(record['start_time'], "%H:%M")
                end = datetime.strptime(record['end_time'], "%H:%M")
                if end < start:
                    end += timedelta(days=1)
                duration = (end - start).total_seconds() / 3600  # ì‹œê°„ ë‹¨ìœ„
                category_times[cat] = category_times.get(cat, 0) + duration
            except:
                pass
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ì‹œê°„ ê³„ì‚°
        for cat in category_counts:
            if category_counts[cat] > 0:
                category_avg_times[cat] = category_times.get(cat, 0) / category_counts[cat]
        
        summary_lines.append("ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ í†µê³„:")
        for cat in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):
            cat_name = cat[0]
            count = cat[1]
            total_hours = category_times.get(cat_name, 0)
            avg_hours = category_avg_times.get(cat_name, 0)
            percentage = (count / stats['total_records'] * 100) if stats['total_records'] > 0 else 0
            summary_lines.append(f"  - {cat_name}:")
            summary_lines.append(f"    * ê¸°ë¡ ìˆ˜: {count}íšŒ ({percentage:.1f}%)")
            summary_lines.append(f"    * ì´ ì‹œê°„: {total_hours:.1f}ì‹œê°„")
            summary_lines.append(f"    * í‰ê·  ì‹œê°„: {avg_hours:.2f}ì‹œê°„/íšŒ")
        summary_lines.append("")
        
        # ì‹œê°„ëŒ€ë³„ í™œë™ íŒ¨í„´ ë¶„ì„
        hourly_counts = {}
        for record in all_records:
            try:
                hour = int(record['start_time'].split(':')[0])
                hourly_counts[hour] = hourly_counts.get(hour, 0) + 1
            except:
                pass
        
        if hourly_counts:
            summary_lines.append("â° ì‹œê°„ëŒ€ë³„ í™œë™ íŒ¨í„´:")
            # ê°€ì¥ í™œë°œí•œ ì‹œê°„ëŒ€
            most_active_hour = max(hourly_counts.items(), key=lambda x: x[1])[0] if hourly_counts else None
            if most_active_hour is not None:
                summary_lines.append(f"  - ê°€ì¥ í™œë°œí•œ ì‹œê°„ëŒ€: {most_active_hour}ì‹œ ({hourly_counts[most_active_hour]}íšŒ)")
            # ì‹œê°„ëŒ€ë³„ ë¶„í¬
            summary_lines.append("  - ì‹œê°„ëŒ€ë³„ í™œë™ ë¶„í¬:")
            for hour in sorted(hourly_counts.keys()):
                summary_lines.append(f"    * {hour}ì‹œ: {hourly_counts[hour]}íšŒ")
            summary_lines.append("")
        
        # ì¼ì¼ í‰ê·  ê¸°ë¡ ìˆ˜
        if unique_dates > 0:
            avg_daily_records = stats['total_records'] / unique_dates
            summary_lines.append(f"ğŸ“… ì¼ì¼ í‰ê·  ê¸°ë¡ ìˆ˜: {avg_daily_records:.1f}ê°œ/ì¼")
            summary_lines.append("")
        
        # ìµœê·¼ í™œë™ íŒ¨í„´ (ìµœê·¼ 7ì¼)
        summary_lines.append("ğŸ“‹ ìµœê·¼ 7ì¼ í™œë™ íŒ¨í„´:")
        recent_week_by_date = {}
        for record in recent_week_records:
            date = record['date']
            if date not in recent_week_by_date:
                recent_week_by_date[date] = []
            recent_week_by_date[date].append(record)
        
        for date in sorted(recent_week_by_date.keys(), reverse=True):
            day_records = recent_week_by_date[date]
            summary_lines.append(f"  - {date}: {len(day_records)}ê°œ ê¸°ë¡")
        summary_lines.append("")
        
        # ì˜¤ëŠ˜ì˜ í™œë™
        today_str = today.isoformat()
        today_records = [r for r in all_records if r['date'] == today_str]
        if today_records:
            summary_lines.append(f"ğŸŒ… ì˜¤ëŠ˜({today_str}) í™œë™:")
            for record in today_records:
                try:
                    start = datetime.strptime(record['start_time'], "%H:%M")
                    end = datetime.strptime(record['end_time'], "%H:%M")
                    if end < start:
                        end += timedelta(days=1)
                    duration = (end - start).total_seconds() / 60  # ë¶„ ë‹¨ìœ„
                    summary_lines.append(f"  - {record['start_time']}-{record['end_time']} ({duration:.0f}ë¶„): {record['activity']} ({record['category']})")
                except:
                    summary_lines.append(f"  - {record['start_time']}-{record['end_time']}: {record['activity']} ({record['category']})")
            summary_lines.append("")
        
        # í™œë™ ì—°ì†ì„± ë¶„ì„ (ìµœê·¼ ê¸°ë¡ì˜ ì¼ê´€ì„±)
        if len(recent_week_records) > 0:
            consecutive_days = 0
            current_date = today
            for i in range(7):
                date_str = current_date.isoformat()
                if any(r['date'] == date_str for r in all_records):
                    consecutive_days += 1
                else:
                    break
                current_date -= timedelta(days=1)
            
            summary_lines.append(f"ğŸ“Š í™œë™ ì—°ì†ì„±: ìµœê·¼ {consecutive_days}ì¼ ì—°ì† ê¸°ë¡")
            summary_lines.append("")
        
        return "\n".join(summary_lines)
    except Exception as e:
        print(f"ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë¡ ë¡œë“œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def get_realtime_feedback() -> dict:
    """
    ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì‹œê°„ í”¼ë“œë°± ìƒì„±
    
    Returns:
        dict: JSON í˜•ì‹ì˜ í”¼ë“œë°± ë°ì´í„°
        {
            "summary": "í•œ ì¤„ ìš”ì•½",
            "feedbacks": [
                {"title": "...", "description": "...", "type": "positive/neutral/suggestion"},
                ...
            ],
            "timestamp": "..."
        }
    """
    try:
        openai_client = get_openai_client()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë¡ ë¡œë“œ
        routine_data_summary = load_database_records_for_feedback()
        
        # í†µê³„ ê¸°ë°˜ ì¢…í•© í”¼ë“œë°± í”„ë¡¬í”„íŠ¸
        feedback_prompt = """ë„ˆëŠ” ì‚¬ìš©ìì˜ ë£¨í‹´ í†µê³„ ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í•˜ë‚˜ì˜ í†µí•©ëœ í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” AI ì½”ì¹˜ì…ë‹ˆë‹¤.

**ì¤‘ìš”: ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**

**ë§íˆ¬ ê·œì¹™:**
- ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ ì¡´ëŒ“ë§ ì‚¬ìš©
- ê²½ì–´ì²´ë¡œ ì‘ì„± ("~í•˜ì„¸ìš”", "~í•˜ì‹œë©´ ë©ë‹ˆë‹¤", "~í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤")
- ì¹œê·¼í•˜ì§€ë§Œ ì „ë¬¸ì ì¸ í†¤ ìœ ì§€
- ê¸ì •ì ì¸ í”¼ë“œë°±ê³¼ ê±´ì„¤ì ì¸ ì œì•ˆì„ ê· í˜•ìˆê²Œ ì œê³µ

**ì¶œë ¥ í˜•ì‹:**
{
  "summary": "í†µê³„ë¥¼ ì¢…í•©í•œ í•œ ì¤„ ìš”ì•½ (50ì ì´ë‚´, ì¡´ëŒ“ë§ë¡œ ì‘ì„±)",
  "feedbacks": [
    {
      "title": "ì¢…í•© í”¼ë“œë°± ì œëª© (ì¡´ëŒ“ë§)",
      "description": "ëª¨ë“  í†µê³„ë¥¼ ì¢…í•©í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°± ì„¤ëª… (ì¡´ëŒ“ë§, í˜„ì‹¤ì ì´ê³  ì‚¬ì‹¤ ê¸°ë°˜)",
      "type": "positive"
    },
    {
      "title": "ì¢…í•© í”¼ë“œë°± ì œëª© (ì¡´ëŒ“ë§)",
      "description": "ëª¨ë“  í†µê³„ë¥¼ ì¢…í•©í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°± ì„¤ëª… (ì¡´ëŒ“ë§, í˜„ì‹¤ì ì´ê³  ì‚¬ì‹¤ ê¸°ë°˜)",
      "type": "suggestion"
    },
    {
      "title": "ì¢…í•© í”¼ë“œë°± ì œëª© (ì¡´ëŒ“ë§)",
      "description": "ëª¨ë“  í†µê³„ë¥¼ ì¢…í•©í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°± ì„¤ëª… (ì¡´ëŒ“ë§, í˜„ì‹¤ì ì´ê³  ì‚¬ì‹¤ ê¸°ë°˜)",
      "type": "neutral"
    }
  ],
  "timestamp": "YYYY-MM-DD HH:MM:SS í˜•ì‹ì˜ í˜„ì¬ ì‹œê°„"
}

**í”¼ë“œë°± ì‘ì„± ê·œì¹™:**
1. ì œê³µëœ í†µê³„ ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í•˜ë‚˜ì˜ í†µí•©ëœ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”
2. í†µê³„ë³„ë¡œ ë”°ë¡œ í”¼ë“œë°±ì„ ë§Œë“¤ì§€ ë§ê³ , ëª¨ë“  í†µê³„ë¥¼ ì¢…í•©í•˜ì—¬ ì „ì²´ì ì¸ íŒ¨í„´ì„ ë¶„ì„í•˜ì„¸ìš”
3. ë‹¤ìŒ í†µê³„ ìš”ì†Œë“¤ì„ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”:
   - ì „ì²´ ê¸°ë¡ ìˆ˜ì™€ ê¸°ë¡ ê¸°ê°„
   - ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë¡ ìˆ˜, ì´ ì‹œê°„, í‰ê·  ì‹œê°„, ë¹„ìœ¨
   - ì‹œê°„ëŒ€ë³„ í™œë™ íŒ¨í„´
   - ì¼ì¼ í‰ê·  ê¸°ë¡ ìˆ˜
   - ìµœê·¼ í™œë™ íŒ¨í„´ê³¼ ì—°ì†ì„±
   - ì˜¤ëŠ˜ì˜ í™œë™
4. ê¸ì •ì ì¸ ì ì„ ë¨¼ì € ì–¸ê¸‰í•˜ê³ , ê°œì„  ê°€ëŠ¥í•œ ì ì„ ê±´ì„¤ì ìœ¼ë¡œ ì œì•ˆí•˜ì„¸ìš”
5. typeì€ "positive" (ê¸ì •ì ), "suggestion" (ì œì•ˆ), "neutral" (ì¤‘ë¦½ì ) ì¤‘ í•˜ë‚˜
6. í˜„ì‹¤ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°±ë§Œ ì œê³µí•˜ì„¸ìš”
7. í†µê³„ ë°ì´í„°ì—ì„œ ë°œê²¬ëœ íŒ¨í„´ê³¼ íŠ¸ë Œë“œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”

**í†µê³„ ì¢…í•© ë¶„ì„ ì‹œ ê³ ë ¤ì‚¬í•­:**
- ì¹´í…Œê³ ë¦¬ë³„ ì‹œê°„ ë¶„ë°°ì˜ ê· í˜• (ìˆ˜ë©´, ì‹ì‚¬, ì¼ê³¼, ìš´ë™, ì·¨ë¯¸, ê¸°íƒ€)
- ê°€ì¥ ë§ì€ ì‹œê°„ì„ íˆ¬ìí•˜ëŠ” ì¹´í…Œê³ ë¦¬ì™€ ê°€ì¥ ì ì€ ì¹´í…Œê³ ë¦¬
- ì‹œê°„ëŒ€ë³„ í™œë™ íŒ¨í„´ (ì–¸ì œ ê°€ì¥ í™œë°œí•œì§€)
- ê¸°ë¡ì˜ ì¼ê´€ì„±ê³¼ ì—°ì†ì„±
- ì¼ì¼ í‰ê·  ê¸°ë¡ ìˆ˜ì™€ ìµœê·¼ íŠ¸ë Œë“œ
- ì˜¤ëŠ˜ì˜ í™œë™ì´ ì „ì²´ íŒ¨í„´ê³¼ ì–´ë–»ê²Œ ì¼ì¹˜í•˜ëŠ”ì§€

**ì˜ˆì‹œ (ì¡´ëŒ“ë§ í†¤, í†µê³„ ì¢…í•©):**
- "ì „ì²´ í†µê³„ë¥¼ ë³´ë‹ˆ ê¾¸ì¤€íˆ ê¸°ë¡ì„ ë‚¨ê¸°ê³  ê³„ì‹œë„¤ìš”! ì¹´í…Œê³ ë¦¬ë³„ ì‹œê°„ ë¶„ë°°ê°€ ì˜ ì´ë£¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤."
- "ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ë¥¼ ì¢…í•©í•´ë³´ë‹ˆ ìš´ë™ ì‹œê°„ì´ ìƒëŒ€ì ìœ¼ë¡œ ì ì€ í¸ì…ë‹ˆë‹¤. ì£¼ 3íšŒ ì •ë„ë¡œ ê·œì¹™ì ìœ¼ë¡œ ëŠ˜ë ¤ë³´ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
- "ì‹œê°„ëŒ€ë³„ íŒ¨í„´ì„ ë³´ë‹ˆ ì˜¤ì „ ì‹œê°„ëŒ€ì— í™œë™ì´ ì§‘ì¤‘ë˜ì–´ ìˆë„¤ìš”. ì €ë… ì‹œê°„ì—ë„ ì¼ë¶€ í™œë™ì„ ë¶„ì‚°ì‹œí‚¤ë©´ ë” ê· í˜•ì¡íŒ í•˜ë£¨ê°€ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤."

**ê·œì¹™:**
1. JSON í˜•ì‹ë§Œ ì¶œë ¥ (ë§ˆí¬ë‹¤ìš´, ì½”ë“œ ë¸”ë¡ ì—†ì´)
2. summaryëŠ” 50ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ (ì¡´ëŒ“ë§, í†µê³„ ì¢…í•© ìš”ì•½)
3. feedbacks ë°°ì—´ì€ ë°˜ë“œì‹œ 3ê°œì˜ í”¼ë“œë°± í¬í•¨
4. typeì€ "positive", "suggestion", "neutral" ì¤‘ í•˜ë‚˜
5. descriptionì€ ëª¨ë“  í†µê³„ë¥¼ ì¢…í•©í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°± (ì¡´ëŒ“ë§, í˜„ì‹¤ì )
6. timestampëŠ” ISO 8601 í˜•ì‹ ë˜ëŠ” "YYYY-MM-DD HH:MM:SS" í˜•ì‹
7. ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” ì¡´ëŒ“ë§ë¡œ ì‘ì„±
8. ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , ì‹¤ì œ í†µê³„ ë°ì´í„°ë§Œ ê¸°ë°˜ìœ¼ë¡œ ì¢…í•© í”¼ë“œë°±
9. í†µê³„ë³„ë¡œ ë”°ë¡œ í”¼ë“œë°±ì„ ë§Œë“¤ì§€ ë§ê³ , ëª¨ë“  í†µê³„ë¥¼ í•˜ë‚˜ë¡œ ì¢…í•©í•˜ì—¬ ë¶„ì„"""
        
        user_message = f"""ì‚¬ìš©ìì˜ ë£¨í‹´ í†µê³„ ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í•˜ë‚˜ì˜ í†µí•©ëœ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.

{routine_data_summary}

ìœ„ í†µê³„ ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, í†µê³„ë³„ë¡œ ë”°ë¡œ í”¼ë“œë°±ì„ ë§Œë“¤ì§€ ë§ê³  ëª¨ë“  í†µê³„ë¥¼ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬ ì¢…í•©ì ì¸ í”¼ë“œë°±ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
- ì¹´í…Œê³ ë¦¬ë³„ í†µê³„, ì‹œê°„ëŒ€ë³„ íŒ¨í„´, ê¸°ë¡ ì—°ì†ì„±, ì¼ì¼ í‰ê·  ë“±ì„ ëª¨ë‘ ì¢…í•©í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”
- ê¸ì •ì ì¸ ì ê³¼ ê°œì„  ê°€ëŠ¥í•œ ì ì„ ê· í˜•ìˆê²Œ ì¡´ëŒ“ë§(ê²½ì–´ì²´)ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
- í†µê³„ ë°ì´í„°ì—ì„œ í™•ì¸ëœ ì‹¤ì œ íŒ¨í„´ê³¼ ì‚¬ì‹¤ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì¢…í•© í”¼ë“œë°±í•˜ì‹œê³ , ì¶”ì¸¡ì´ë‚˜ ì´ìƒì ì¸ ì¡°ì–¸ì€ í”¼í•´ì£¼ì„¸ìš”"""
        
        completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": feedback_prompt},
                {"role": "user", "content": user_message}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        
        response_content = completion.choices[0].message.content
        
        # JSON íŒŒì‹±
        try:
            result = json.loads(response_content)
            # timestamp ì¶”ê°€ (ì—†ëŠ” ê²½ìš°)
            if "timestamp" not in result:
                result["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            return result
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
            return {
                "summary": "í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "feedbacks": [
                    {
                        "title": "ë‹¤ì‹œ ì‹œë„",
                        "description": "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                        "type": "neutral"
                    }
                ],
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
    
    except Exception as e:
        error_str = str(e)
        # ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼ ì˜¤ë¥˜ ì²˜ë¦¬
        if "insufficient_quota" in error_str or "429" in error_str:
            return {
                "summary": "API ì‚¬ìš©ëŸ‰ í•œë„ê°€ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "feedbacks": [
                    {
                        "title": "OpenAI ê³„ì • í™•ì¸",
                        "description": "OpenAI ê³„ì •ì˜ ê²°ì œ ì •ë³´ì™€ ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
                        "type": "neutral"
                    }
                ],
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ
        return {
            "summary": "í”¼ë“œë°±ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "feedbacks": [
                {
                    "title": "ì˜¤ë¥˜ ë°œìƒ",
                    "description": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                    "type": "neutral"
                }
            ],
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

def get_ai_advice(user_input: str) -> dict:
    """
    ì‚¬ìš©ì ì…ë ¥ê³¼ CSV ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ì¡°ì–¸ ìƒì„±
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
    
    Returns:
        dict: JSON í˜•ì‹ì˜ ì¡°ì–¸ ë°ì´í„°
        {
            "summary": "í•œ ì¤„ ìš”ì•½",
            "advices": [
                {"title": "...", "description": "...", "priority": 1},
                ...
            ],
            "timestamp": "..."
        }
    """
    try:
        openai_client = get_openai_client()
        
        # CSV ë°ì´í„° ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        try:
            with open("ai_advice_with_data_prompt.md", "r", encoding="utf-8") as f:
                content = f.read()
                start = content.find("`") + 1
                end = content.rfind("`")
                if start > 0 and end > start:
                    ai_prompt = content[start:end].strip()
                else:
                    ai_prompt = load_ai_prompt()  # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        except:
            ai_prompt = load_ai_prompt()  # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        
        # CSV ë°ì´í„° ë¡œë“œ
        routine_data_summary = load_routine_data_for_advice()
        
        # ì‚¬ìš©ì ì…ë ¥ê³¼ ë°ì´í„°ë¥¼ ê²°í•©
        user_message = f"""ì‚¬ìš©ì ì§ˆë¬¸/ê³ ë¯¼: {user_input}

{routine_data_summary}

ìœ„ ë£¨í‹´ ë°ì´í„°ë¥¼ ë°˜ë“œì‹œ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, ì‚¬ìš©ìì˜ ì§ˆë¬¸/ê³ ë¯¼ì— ëŒ€í•œ í˜„ì‹¤ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ ì¡´ëŒ“ë§(ê²½ì–´ì²´)ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. 
ë°ì´í„°ì—ì„œ í™•ì¸ëœ ì‹¤ì œ íŒ¨í„´ê³¼ ì‚¬ì‹¤ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì¡°ì–¸í•˜ì‹œê³ , ì¶”ì¸¡ì´ë‚˜ ì´ìƒì ì¸ ì¡°ì–¸ì€ í”¼í•´ì£¼ì„¸ìš”."""
        
        completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": ai_prompt},
                {"role": "user", "content": user_message}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        
        response_content = completion.choices[0].message.content
        
        # JSON íŒŒì‹±
        try:
            result = json.loads(response_content)
            # timestamp ì¶”ê°€ (ì—†ëŠ” ê²½ìš°)
            if "timestamp" not in result:
                result["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            return result
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
            return {
                "summary": "ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "advices": [
                    {
                        "title": "ë‹¤ì‹œ ì‹œë„",
                        "description": "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                        "priority": 1
                    }
                ],
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
    
    except Exception as e:
        error_str = str(e)
        # ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼ ì˜¤ë¥˜ ì²˜ë¦¬
        if "insufficient_quota" in error_str or "429" in error_str:
            return {
                "summary": "API ì‚¬ìš©ëŸ‰ í•œë„ê°€ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "advices": [
                    {
                        "title": "OpenAI ê³„ì • í™•ì¸",
                        "description": "OpenAI ê³„ì •ì˜ ê²°ì œ ì •ë³´ì™€ ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. https://platform.openai.com/usage ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                        "priority": 1
                    },
                    {
                        "title": "í¬ë ˆë”§ ì¶©ì „",
                        "description": "OpenAI ê³„ì •ì— í¬ë ˆë”§ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²°ì œ ì •ë³´ë¥¼ í™•ì¸í•˜ê³  í•„ìš”ì‹œ í¬ë ˆë”§ì„ ì¶©ì „í•´ì£¼ì„¸ìš”.",
                        "priority": 2
                    },
                    {
                        "title": "ì ì‹œ í›„ ì¬ì‹œë„",
                        "description": "ì‚¬ìš©ëŸ‰ í•œë„ê°€ ë¦¬ì…‹ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì‹œê±°ë‚˜, ë‹¤ë¥¸ API í‚¤ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”.",
                        "priority": 3
                    }
                ],
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ
        return {
            "summary": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "advices": [
                {
                    "title": "API í‚¤ í™•ì¸",
                    "description": "OPENAI_API_KEYê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.",
                    "priority": 1
                },
                {
                    "title": "ë„¤íŠ¸ì›Œí¬ í™•ì¸",
                    "description": "ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
                    "priority": 2
                },
                {
                    "title": "ë‹¤ì‹œ ì‹œë„",
                    "description": "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                    "priority": 3
                }
            ],
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

def load_routine_category_prompt():
    """ë£¨í‹´ ì¹´í…Œê³ ë¦¬ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
    try:
        with open("routine_category_prompt.md", "r", encoding="utf-8") as f:
            content = f.read()
            # export const ROUTINE_CATEGORY_PROMPT = `...` í˜•ì‹ì—ì„œ í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ
            # ì²« ë²ˆì§¸ ë°±í‹±(`)ê³¼ ë§ˆì§€ë§‰ ë°±í‹±(`) ì‚¬ì´ì˜ ë‚´ìš© ì¶”ì¶œ
            start = content.find("`") + 1
            end = content.rfind("`")
            if start > 0 and end > start:
                prompt_text = content[start:end].strip()
                # ì²« ì¤„ì´ export constë¡œ ì‹œì‘í•˜ë©´ ì œê±°
                lines = prompt_text.split('\n')
                if lines and 'export const' in lines[0]:
                    prompt_text = '\n'.join(lines[1:])
                return prompt_text
    except Exception as e:
        print(f"í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
        pass
    
    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
    return """ë„ˆëŠ” ì‚¬ìš©ìì˜ ì¼ìƒ ë£¨í‹´ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¥¼ ì œì•ˆí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.

**ì¤‘ìš”: ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•´. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆ.**

**ì¶œë ¥ í˜•ì‹:**
{
  "suggested_category": "ì œì•ˆëœ ì¹´í…Œê³ ë¦¬ëª…",
  "category_description": "ì¹´í…Œê³ ë¦¬ ì„¤ëª… (50ì ì´ë‚´)",
  "alternative_categories": [
    {"name": "ëŒ€ì•ˆ ì¹´í…Œê³ ë¦¬", "reason": "ì´ìœ  ì„¤ëª…"}
  ],
  "routines": [
    {"name": "ì œì•ˆ ë£¨í‹´ëª…", "description": "ë£¨í‹´ ì„¤ëª…", "time_estimate": "ì˜ˆìƒ ì†Œìš” ì‹œê°„"}
  ],
  "timestamp": "YYYY-MM-DD HH:MM:SS í˜•ì‹ì˜ í˜„ì¬ ì‹œê°„"
}"""

def get_routine_category_suggestion(user_input: str) -> dict:
    """
    ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ë£¨í‹´ ì¹´í…Œê³ ë¦¬ ì œì•ˆ ìƒì„±
    
    Args:
        user_input: ì‚¬ìš©ìê°€ ì…ë ¥í•œ í™œë™/ë£¨í‹´ ë‚´ìš©
    
    Returns:
        dict: JSON í˜•ì‹ì˜ ì¹´í…Œê³ ë¦¬ ì œì•ˆ ë°ì´í„°
    """
    try:
        openai_client = get_openai_client()
        category_prompt = load_routine_category_prompt()
        
        completion = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": category_prompt},
                {"role": "user", "content": f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ í™œë™: {user_input}\n\nì´ í™œë™ì— ì í•©í•œ ì¹´í…Œê³ ë¦¬ì™€ ê´€ë ¨ ë£¨í‹´ì„ ì œì•ˆí•´ì£¼ì„¸ìš”."}
            ],
            temperature=0.7,
            max_tokens=800
        )
        
        response_content = completion.choices[0].message.content
        
        # JSON íŒŒì‹±
        try:
            result = json.loads(response_content)
            # timestamp ì¶”ê°€ (ì—†ëŠ” ê²½ìš°)
            if "timestamp" not in result:
                result["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            return result
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
            return {
                "suggested_category": "ê¸°íƒ€",
                "category_description": "ì¹´í…Œê³ ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "alternative_categories": [
                    {"name": "ì‹ì‚¬", "reason": "ì¼ë°˜ì ì¸ ì‹ì‚¬ í™œë™ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤"}
                ],
                "routines": [
                    {
                        "name": user_input,
                        "description": "ì‚¬ìš©ìê°€ ì…ë ¥í•œ í™œë™",
                        "time_estimate": "30ë¶„"
                    }
                ],
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
    
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ
        return {
            "suggested_category": "ê¸°íƒ€",
            "category_description": "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "alternative_categories": [
                {"name": "ì‹ì‚¬", "reason": "ê¸°ë³¸ ì¹´í…Œê³ ë¦¬"}
            ],
            "routines": [
                {
                    "name": user_input if user_input else "ìƒˆ ë£¨í‹´",
                    "description": "ì‚¬ìš©ìê°€ ì…ë ¥í•œ í™œë™",
                    "time_estimate": "30ë¶„"
                }
            ],
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
